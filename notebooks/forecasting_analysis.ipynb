{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Model Market Forecasting & Risk Engine\n",
                "\n",
                "A rigorous time-series forecasting pipeline comparing three modelling paradigms:\n",
                "\n",
                "| Model | Type | Strength |\n",
                "|-------|------|----------|\n",
                "| **ARIMA-GARCH** | Econometric | Explicit volatility modelling, fat tails |\n",
                "| **XGBoost** | Machine Learning | Non-linear feature interactions |\n",
                "| **LSTM** | Deep Learning | Sequential dependency learning |\n",
                "\n",
                "---\n",
                "\n",
                "## Table of Contents\n",
                "\n",
                "1. [Setup & Configuration](#setup)\n",
                "2. [Data Ingestion](#data)\n",
                "3. **Part A: ARIMA-GARCH** (Steps 1-10)\n",
                "4. **Part B: XGBoost**\n",
                "5. **Part C: LSTM**\n",
                "6. **Part D: Consolidated Comparison**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='setup'></a>\n",
                "## 0. Setup & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === GLOBAL CONFIGURATION ===\n",
                "TICKER = \"SPY\"              # Asset to analyze\n",
                "START_DATE = \"2018-01-01\"   # Training start\n",
                "END_DATE = \"2024-12-31\"     # Training end \n",
                "TEST_SIZE = 56              # Out-of-sample test days (~2.5 months)\n",
                "RANDOM_SEED = 42\n",
                "# ============================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from dotenv import load_dotenv\n",
                "from statsmodels.tsa.stattools import adfuller\n",
                "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
                "from statsmodels.tsa.arima.model import ARIMA\n",
                "from arch import arch_model\n",
                "from scipy import stats\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "import xgboost as xgb\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from tqdm.notebook import tqdm\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "\n",
                "# Reproducibility\n",
                "np.random.seed(RANDOM_SEED)\n",
                "torch.manual_seed(RANDOM_SEED)\n",
                "\n",
                "# Plotting style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (14, 5)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "print(\"✓ All imports successful.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id='data'></a>\n",
                "## 1. Data Ingestion & Preprocessing\n",
                "\n",
                "**Primary Source:** Alpaca Markets API  \n",
                "**Fallback:** Yahoo Finance (yfinance)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def fetch_data_alpaca(ticker, start, end):\n",
                "    \"\"\"Fetch data from Alpaca Markets API (primary source).\"\"\"\n",
                "    try:\n",
                "        from alpaca_trade_api import REST\n",
                "        \n",
                "        api_key = os.getenv('ALPACA_API_KEY')\n",
                "        secret_key = os.getenv('ALPACA_SECRET_KEY')\n",
                "        endpoint = os.getenv('ALPACA_ENDPOINT', 'https://paper-api.alpaca.markets')\n",
                "        \n",
                "        if not api_key or api_key == 'your_api_key_here':\n",
                "            print(\"⚠ Alpaca API key not configured. Falling back to yfinance.\")\n",
                "            return None\n",
                "        \n",
                "        api = REST(api_key, secret_key, endpoint)\n",
                "        \n",
                "        # Fetch bars\n",
                "        bars = api.get_bars(\n",
                "            ticker,\n",
                "            '1Day',\n",
                "            start=start,\n",
                "            end=end,\n",
                "            adjustment='all'  # Split and dividend adjusted\n",
                "        ).df\n",
                "        \n",
                "        if bars.empty:\n",
                "            print(f\"⚠ No data returned from Alpaca for {ticker}. Falling back to yfinance.\")\n",
                "            return None\n",
                "            \n",
                "        # Rename columns to match expected format\n",
                "        bars = bars.reset_index()\n",
                "        bars = bars.rename(columns={'timestamp': 'Date', 'close': 'Price'})\n",
                "        bars = bars[['Date', 'Price']]\n",
                "        bars['Date'] = pd.to_datetime(bars['Date']).dt.tz_localize(None)\n",
                "        bars = bars.set_index('Date')\n",
                "        \n",
                "        print(f\"✓ Data fetched from Alpaca: {len(bars)} observations\")\n",
                "        return bars\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"⚠ Alpaca fetch failed: {e}. Falling back to yfinance.\")\n",
                "        return None\n",
                "\n",
                "\n",
                "def fetch_data_yfinance(ticker, start, end):\n",
                "    \"\"\"Fetch data from Yahoo Finance (fallback source).\"\"\"\n",
                "    import yfinance as yf\n",
                "    \n",
                "    raw_df = yf.download(ticker, start=start, end=end, progress=False, auto_adjust=True)\n",
                "    \n",
                "    if raw_df.empty:\n",
                "        raise ValueError(f\"No data returned from yfinance for {ticker}\")\n",
                "    \n",
                "    # Handle both single and multi-ticker column formats\n",
                "    if isinstance(raw_df.columns, pd.MultiIndex):\n",
                "        # Multi-ticker format: ('Close', 'SPY')\n",
                "        df = raw_df['Close'].to_frame()\n",
                "        df.columns = ['Price']\n",
                "    else:\n",
                "        # Single-ticker format: 'Close'\n",
                "        df = raw_df[['Close']].copy()\n",
                "        df.columns = ['Price']\n",
                "    \n",
                "    df.index.name = 'Date'\n",
                "    print(f\"✓ Data fetched from Yahoo Finance: {len(df)} observations\")\n",
                "    return df\n",
                "\n",
                "\n",
                "def fetch_data(ticker, start, end):\n",
                "    \"\"\"Unified data fetcher: Alpaca first, yfinance fallback.\"\"\"\n",
                "    print(f\"Fetching {ticker} from {start} to {end}...\")\n",
                "    \n",
                "    # Try Alpaca first\n",
                "    df = fetch_data_alpaca(ticker, start, end)\n",
                "    \n",
                "    # Fallback to yfinance\n",
                "    if df is None:\n",
                "        df = fetch_data_yfinance(ticker, start, end)\n",
                "    \n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fetch Data\n",
                "df = fetch_data(TICKER, START_DATE, END_DATE)\n",
                "\n",
                "# Compute Returns\n",
                "df['Return'] = np.log(df['Price'] / df['Price'].shift(1))\n",
                "df['PriceChange'] = df['Price'].diff()  # For ARIMA on levels\n",
                "df.dropna(inplace=True)\n",
                "\n",
                "print(f\"\\n✓ Final dataset: {len(df)} observations\")\n",
                "print(f\"  Date Range: {df.index[0].date()} to {df.index[-1].date()}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot\n",
                "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
                "\n",
                "axes[0].plot(df.index, df['Price'], 'b-', linewidth=1)\n",
                "axes[0].set_title(f'{TICKER} Price Series')\n",
                "axes[0].set_ylabel('Price ($)')\n",
                "\n",
                "axes[1].plot(df.index, df['Return'], 'k-', alpha=0.7, linewidth=0.8)\n",
                "axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
                "axes[1].set_title(f'{TICKER} Log Returns')\n",
                "axes[1].set_ylabel('Log Return')\n",
                "axes[1].set_xlabel('Date')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part A: ARIMA-GARCH\n",
                "\n",
                "**Methodology:** 10-step diagnostic pipeline for rigorous econometric modelling."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A.1: Stationarity Test (ADF)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def adf_test(series, name='Series'):\n",
                "    result = adfuller(series.dropna(), autolag='AIC')\n",
                "    print(f\"ADF Test: {name}\")\n",
                "    print(f\"  Statistic: {result[0]:.4f}\")\n",
                "    print(f\"  p-value:   {result[1]:.4f}\")\n",
                "    print(f\"  Lags Used: {result[2]}\")\n",
                "    print(f\"  Stationary: {'Yes ✓' if result[1] < 0.05 else 'No ✗'}\")\n",
                "    return result[1] < 0.05\n",
                "\n",
                "print(\"=\" * 40)\n",
                "adf_test(df['Price'], 'Raw Price')\n",
                "print(\"=\" * 40)\n",
                "adf_test(df['PriceChange'], 'Price Change (d=1)')\n",
                "print(\"=\" * 40)\n",
                "is_stationary = adf_test(df['Return'], 'Log Returns')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A.2: Mean Model Selection (AR Order)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use Returns (stationary series) for GARCH\n",
                "series = df['Return'].dropna()\n",
                "\n",
                "# Test for significant mean (intercept)\n",
                "t_stat, p_val = stats.ttest_1samp(series, 0)\n",
                "USE_INTERCEPT = p_val < 0.05\n",
                "print(f\"T-test for mean≠0: p={p_val:.4f} → {'Include' if USE_INTERCEPT else 'Exclude'} intercept\")\n",
                "\n",
                "# AR Order Selection\n",
                "ar_aic = {}\n",
                "trend = 'c' if USE_INTERCEPT else 'n'\n",
                "\n",
                "for p in range(1, 6):\n",
                "    try:\n",
                "        fit = ARIMA(series, order=(p, 0, 0), trend=trend).fit()\n",
                "        ar_aic[p] = fit.aic\n",
                "    except:\n",
                "        ar_aic[p] = np.inf\n",
                "\n",
                "AR_ORDER = min(ar_aic, key=ar_aic.get)\n",
                "print(f\"\\nAR Order Selection (AIC):\")\n",
                "for p, aic in ar_aic.items():\n",
                "    marker = \" ← BEST\" if p == AR_ORDER else \"\"\n",
                "    print(f\"  AR({p}): AIC = {aic:.2f}{marker}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A.3: GARCH Distribution Selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scale returns (GARCH numerical stability)\n",
                "scaled_series = series * 100\n",
                "\n",
                "distributions = ['normal', 't', 'skewt']\n",
                "garch_results = {}\n",
                "\n",
                "print(\"GARCH(1,1) Distribution Selection:\")\n",
                "for dist in distributions:\n",
                "    try:\n",
                "        am = arch_model(scaled_series, mean='AR', lags=AR_ORDER, vol='Garch', p=1, q=1, dist=dist)\n",
                "        fit = am.fit(disp='off')\n",
                "        garch_results[dist] = {'fit': fit, 'aic': fit.aic}\n",
                "        print(f\"  {dist:8s}: AIC = {fit.aic:.2f}\")\n",
                "    except Exception as e:\n",
                "        print(f\"  {dist:8s}: FAILED ({e})\")\n",
                "\n",
                "BEST_DIST = min(garch_results, key=lambda x: garch_results[x]['aic'])\n",
                "best_garch_fit = garch_results[BEST_DIST]['fit']\n",
                "print(f\"\\n✓ Selected: AR({AR_ORDER})-GARCH(1,1) with {BEST_DIST} innovations\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(best_garch_fit.summary())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A.4: In-Sample Volatility Bands"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cond_vol = best_garch_fit.conditional_volatility / 100\n",
                "aligned_series = series.iloc[-len(cond_vol):]\n",
                "\n",
                "inside = (aligned_series.values > -2*cond_vol.values) & (aligned_series.values < 2*cond_vol.values)\n",
                "coverage = inside.mean()\n",
                "\n",
                "plt.figure(figsize=(14, 6))\n",
                "plt.plot(aligned_series.index, aligned_series.values, 'k-', alpha=0.7, label='Returns')\n",
                "plt.fill_between(aligned_series.index, -2*cond_vol.values, 2*cond_vol.values, \n",
                "                 alpha=0.3, color='orange', label=f'±2σ (Coverage: {coverage:.1%})')\n",
                "plt.axhline(0, color='red', linestyle='--', alpha=0.3)\n",
                "plt.title('GARCH In-Sample Volatility Bands')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A.5: Walk-Forward Backtest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_end = len(series) - TEST_SIZE\n",
                "\n",
                "arima_forecasts = []\n",
                "garch_forecasts = []\n",
                "garch_sigmas = []\n",
                "actuals = []\n",
                "dates = []\n",
                "\n",
                "for i in tqdm(range(TEST_SIZE), desc=\"ARIMA-GARCH Backtest\"):\n",
                "    train = series.iloc[:train_end + i]\n",
                "    actual = series.iloc[train_end + i]\n",
                "    date = series.index[train_end + i]\n",
                "    \n",
                "    # ARIMA baseline\n",
                "    try:\n",
                "        ar_fit = ARIMA(train, order=(AR_ORDER, 0, 0), trend=trend).fit()\n",
                "        ar_fc = ar_fit.forecast(steps=1).iloc[0]\n",
                "    except:\n",
                "        ar_fc = 0.0\n",
                "    \n",
                "    # AR-GARCH\n",
                "    try:\n",
                "        am = arch_model(train * 100, mean='AR', lags=AR_ORDER, vol='Garch', p=1, q=1, dist=BEST_DIST)\n",
                "        g_fit = am.fit(disp='off', show_warning=False)\n",
                "        fc = g_fit.forecast(horizon=1, reindex=False)\n",
                "        mean_fc = fc.mean.iloc[-1, 0] / 100\n",
                "        vol_fc = np.sqrt(fc.variance.iloc[-1, 0]) / 100\n",
                "    except:\n",
                "        mean_fc, vol_fc = 0.0, 0.01\n",
                "    \n",
                "    arima_forecasts.append(ar_fc)\n",
                "    garch_forecasts.append(mean_fc)\n",
                "    garch_sigmas.append(vol_fc)\n",
                "    actuals.append(actual)\n",
                "    dates.append(date)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Store ARIMA-GARCH results\n",
                "arima_results = pd.DataFrame({\n",
                "    'Date': dates,\n",
                "    'Actual': actuals,\n",
                "    'ARIMA_Pred': arima_forecasts,\n",
                "    'GARCH_Pred': garch_forecasts,\n",
                "    'GARCH_Sigma': garch_sigmas\n",
                "}).set_index('Date')\n",
                "\n",
                "arima_mse = mean_squared_error(arima_results['Actual'], arima_results['ARIMA_Pred'])\n",
                "garch_mse = mean_squared_error(arima_results['Actual'], arima_results['GARCH_Pred'])\n",
                "\n",
                "print(f\"MSE (ARIMA only):  {arima_mse:.8f}\")\n",
                "print(f\"MSE (AR-GARCH):    {garch_mse:.8f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part B: XGBoost\n",
                "\n",
                "**Methodology:** Gradient Boosted Trees on lagged features with strict time-series validation."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### B.1: Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create lagged features\n",
                "N_LAGS = 5\n",
                "VOL_WINDOW = 21\n",
                "\n",
                "feature_df = df[['Return']].copy()\n",
                "\n",
                "for lag in range(1, N_LAGS + 1):\n",
                "    feature_df[f'lag_{lag}'] = feature_df['Return'].shift(lag)\n",
                "\n",
                "feature_df['rolling_vol'] = feature_df['Return'].shift(1).rolling(VOL_WINDOW).std()\n",
                "feature_df['ewma_vol'] = feature_df['Return'].shift(1).ewm(span=VOL_WINDOW).std()\n",
                "\n",
                "feature_df.dropna(inplace=True)\n",
                "\n",
                "# Define X and y\n",
                "FEATURE_COLS = [c for c in feature_df.columns if c != 'Return']\n",
                "X_full = feature_df[FEATURE_COLS]\n",
                "y_full = feature_df['Return']\n",
                "\n",
                "print(f\"Features: {FEATURE_COLS}\")\n",
                "print(f\"Total samples: {len(X_full)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### B.2: Walk-Forward Backtest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_end = len(X_full) - TEST_SIZE\n",
                "\n",
                "xgb_forecasts = []\n",
                "xgb_actuals = []\n",
                "xgb_dates = []\n",
                "\n",
                "XGB_PARAMS = {\n",
                "    'n_estimators': 100,\n",
                "    'max_depth': 3,\n",
                "    'learning_rate': 0.05,\n",
                "    'objective': 'reg:squarederror',\n",
                "    'verbosity': 0,\n",
                "    'n_jobs': -1,\n",
                "    'random_state': RANDOM_SEED\n",
                "}\n",
                "\n",
                "for i in tqdm(range(TEST_SIZE), desc=\"XGBoost Backtest\"):\n",
                "    # Split\n",
                "    X_train = X_full.iloc[:train_end + i]\n",
                "    y_train = y_full.iloc[:train_end + i]\n",
                "    X_test = X_full.iloc[[train_end + i]]\n",
                "    y_test = y_full.iloc[train_end + i]\n",
                "    \n",
                "    # Scale (fit on train only!)\n",
                "    scaler = StandardScaler()\n",
                "    X_train_scaled = scaler.fit_transform(X_train)\n",
                "    X_test_scaled = scaler.transform(X_test)\n",
                "    \n",
                "    # Train\n",
                "    model = xgb.XGBRegressor(**XGB_PARAMS)\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    \n",
                "    # Predict\n",
                "    pred = model.predict(X_test_scaled)[0]\n",
                "    \n",
                "    xgb_forecasts.append(pred)\n",
                "    xgb_actuals.append(y_test)\n",
                "    xgb_dates.append(X_full.index[train_end + i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb_results = pd.DataFrame({\n",
                "    'Date': xgb_dates,\n",
                "    'Actual': xgb_actuals,\n",
                "    'XGB_Pred': xgb_forecasts\n",
                "}).set_index('Date')\n",
                "\n",
                "xgb_mse = mean_squared_error(xgb_results['Actual'], xgb_results['XGB_Pred'])\n",
                "print(f\"XGBoost MSE: {xgb_mse:.8f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part C: LSTM\n",
                "\n",
                "**Methodology:** Recurrent Neural Network with sequence-based input."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### C.1: LSTM Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LSTMNet(nn.Module):\n",
                "    def __init__(self, input_size, hidden_size=32, num_layers=1):\n",
                "        super().__init__()\n",
                "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
                "        self.fc = nn.Linear(hidden_size, 1)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        out, _ = self.lstm(x)\n",
                "        return self.fc(out[:, -1, :])\n",
                "\n",
                "# Hyperparameters\n",
                "LSTM_CONFIG = {\n",
                "    'hidden_size': 32,\n",
                "    'num_layers': 1,\n",
                "    'epochs': 30,\n",
                "    'lr': 0.01,\n",
                "    'seq_length': 10\n",
                "}\n",
                "\n",
                "print(f\"LSTM Config: {LSTM_CONFIG}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### C.2: Sequence Creation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_sequences(X, y, seq_len):\n",
                "    X_seq, y_seq = [], []\n",
                "    for i in range(seq_len, len(X)):\n",
                "        X_seq.append(X[i-seq_len:i])\n",
                "        y_seq.append(y[i])\n",
                "    return np.array(X_seq), np.array(y_seq)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### C.3: Walk-Forward Backtest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lstm_forecasts = []\n",
                "lstm_actuals = []\n",
                "lstm_dates = []\n",
                "\n",
                "SEQ_LEN = LSTM_CONFIG['seq_length']\n",
                "train_end = len(X_full) - TEST_SIZE\n",
                "\n",
                "for i in tqdm(range(TEST_SIZE), desc=\"LSTM Backtest\"):\n",
                "    # Expanding window\n",
                "    X_train = X_full.iloc[:train_end + i].values\n",
                "    y_train = y_full.iloc[:train_end + i].values\n",
                "    \n",
                "    # Scale\n",
                "    scaler_X = StandardScaler()\n",
                "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
                "    \n",
                "    # Create sequences\n",
                "    X_seq, y_seq = create_sequences(X_train_scaled, y_train, SEQ_LEN)\n",
                "    \n",
                "    if len(X_seq) < 10:\n",
                "        lstm_forecasts.append(0.0)\n",
                "        lstm_actuals.append(y_full.iloc[train_end + i])\n",
                "        lstm_dates.append(X_full.index[train_end + i])\n",
                "        continue\n",
                "    \n",
                "    # Tensors\n",
                "    X_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
                "    y_tensor = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(1)\n",
                "    \n",
                "    # Model\n",
                "    model = LSTMNet(X_train.shape[1], LSTM_CONFIG['hidden_size'], LSTM_CONFIG['num_layers'])\n",
                "    optimizer = optim.Adam(model.parameters(), lr=LSTM_CONFIG['lr'])\n",
                "    criterion = nn.MSELoss()\n",
                "    \n",
                "    # Train\n",
                "    model.train()\n",
                "    for _ in range(LSTM_CONFIG['epochs']):\n",
                "        optimizer.zero_grad()\n",
                "        out = model(X_tensor)\n",
                "        loss = criterion(out, y_tensor)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "    \n",
                "    # Predict: use last SEQ_LEN rows\n",
                "    X_test_raw = X_full.iloc[train_end + i - SEQ_LEN + 1 : train_end + i + 1].values\n",
                "    X_test_scaled = scaler_X.transform(X_test_raw)\n",
                "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(0)\n",
                "    \n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        pred = model(X_test_tensor).item()\n",
                "    \n",
                "    lstm_forecasts.append(pred)\n",
                "    lstm_actuals.append(y_full.iloc[train_end + i])\n",
                "    lstm_dates.append(X_full.index[train_end + i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lstm_results = pd.DataFrame({\n",
                "    'Date': lstm_dates,\n",
                "    'Actual': lstm_actuals,\n",
                "    'LSTM_Pred': lstm_forecasts\n",
                "}).set_index('Date')\n",
                "\n",
                "lstm_mse = mean_squared_error(lstm_results['Actual'], lstm_results['LSTM_Pred'])\n",
                "print(f\"LSTM MSE: {lstm_mse:.8f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part D: Consolidated Comparison\n",
                "\n",
                "**Objective:** Compare all three models on the same out-of-sample test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Merge all results\n",
                "comparison = arima_results[['Actual', 'GARCH_Pred']].copy()\n",
                "comparison['XGB_Pred'] = xgb_results['XGB_Pred']\n",
                "comparison['LSTM_Pred'] = lstm_results['LSTM_Pred']\n",
                "\n",
                "comparison.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute metrics for each model\n",
                "def compute_metrics(actual, predicted):\n",
                "    mse = mean_squared_error(actual, predicted)\n",
                "    mae = mean_absolute_error(actual, predicted)\n",
                "    # Direction accuracy\n",
                "    dir_acc = np.mean(np.sign(actual) == np.sign(predicted))\n",
                "    return {'MSE': mse, 'MAE': mae, 'Direction Acc': dir_acc}\n",
                "\n",
                "metrics = {\n",
                "    'ARIMA-GARCH': compute_metrics(comparison['Actual'], comparison['GARCH_Pred']),\n",
                "    'XGBoost': compute_metrics(comparison['Actual'], comparison['XGB_Pred']),\n",
                "    'LSTM': compute_metrics(comparison['Actual'], comparison['LSTM_Pred'])\n",
                "}\n",
                "\n",
                "metrics_df = pd.DataFrame(metrics).T\n",
                "metrics_df = metrics_df.sort_values('MSE')\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(f\"MODEL COMPARISON: {TICKER} ({TEST_SIZE}-day backtest)\")\n",
                "print(\"=\" * 50)\n",
                "display(metrics_df.round(6))\n",
                "print(f\"\\n✓ BEST MODEL (by MSE): {metrics_df.index[0]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization\n",
                "fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
                "\n",
                "models = ['GARCH_Pred', 'XGB_Pred', 'LSTM_Pred']\n",
                "titles = ['ARIMA-GARCH', 'XGBoost', 'LSTM']\n",
                "colors = ['red', 'green', 'purple']\n",
                "\n",
                "for ax, model, title, color in zip(axes, models, titles, colors):\n",
                "    ax.plot(comparison.index, comparison['Actual'], 'k-', label='Actual', alpha=0.8, linewidth=1.5)\n",
                "    ax.plot(comparison.index, comparison[model], color=color, linestyle='--', label=f'{title} Prediction', alpha=0.8)\n",
                "    ax.axhline(0, color='gray', linestyle=':', alpha=0.3)\n",
                "    ax.set_title(f'{title} Forecast vs Actual')\n",
                "    ax.set_ylabel('Return')\n",
                "    ax.legend(loc='upper right')\n",
                "\n",
                "axes[-1].set_xlabel('Date')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bar chart comparison\n",
                "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
                "\n",
                "for i, metric in enumerate(['MSE', 'MAE', 'Direction Acc']):\n",
                "    values = metrics_df[metric].values\n",
                "    colors = ['green' if v == values.min() else 'steelblue' for v in values] if metric != 'Direction Acc' else \\\n",
                "             ['green' if v == values.max() else 'steelblue' for v in values]\n",
                "    \n",
                "    axes[i].bar(metrics_df.index, values, color=colors)\n",
                "    axes[i].set_title(metric)\n",
                "    axes[i].set_ylabel(metric)\n",
                "    for j, v in enumerate(values):\n",
                "        axes[i].text(j, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Final Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(f\"FINAL REPORT: {TICKER}\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nData: {START_DATE} to {END_DATE} ({len(df)} obs)\")\n",
                "print(f\"Backtest: Last {TEST_SIZE} days (walk-forward)\")\n",
                "print(f\"\\n{'Model':<15} {'MSE':<12} {'MAE':<12} {'Dir Acc':<12}\")\n",
                "print(\"-\" * 51)\n",
                "for model, row in metrics_df.iterrows():\n",
                "    print(f\"{model:<15} {row['MSE']:<12.6f} {row['MAE']:<12.6f} {row['Direction Acc']:<12.2%}\")\n",
                "print(\"-\" * 51)\n",
                "print(f\"\\n✓ Winner (MSE): {metrics_df.index[0]}\")\n",
                "print(f\"✓ Winner (Direction): {metrics_df.sort_values('Direction Acc', ascending=False).index[0]}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}